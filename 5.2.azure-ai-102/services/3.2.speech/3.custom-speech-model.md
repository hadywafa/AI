# ğŸ—£ï¸ Azure AI Speech â€“ Custom Speech Models

> âœ… **Official Definition**:
> Azure **Custom Speech** lets you improve Microsoftâ€™s speech-to-text accuracy for your specific vocabulary, noise conditions, or speaking styles â€” by training a custom version of the speech recognition model using your **own audio + text data**.

---

## ğŸ¯ Why Use Custom Speech?

Azure's **default speech-to-text** model is already excellent. But sometimes, it might **mishear names**, **company brands**, or **domain-specific terms**. Example?

ğŸ§  Default model might hear:

> "Wasaap is popular in U.A.E"

And transcribe as:

> âŒ â€œWas up is popular in U.A.Eâ€

Because it doesn't know you meant **WhatsApp**.

With **Custom Speech**, you train the model using **examples of how people speak in your app, company, or language style**, so the model gets smarter about your content!

---

## ğŸ§ª Real-Life Scenario

Imagine your company in **Dubai** builds a ride-hailing app called **â€œGoDriveâ€**. You notice Azureâ€™s default model often mishears that as:

- â€œGo driveâ€
- â€œGood driveâ€
- â€œGo dryâ€

To fix this, you train a custom model so that:

ğŸ—£ï¸ When someone says:

> â€œOpen GoDrive appâ€
> The model always outputs:
> âœ… â€œOpen GoDrive appâ€

ğŸ¯ Goal: make the model recognize **your important terms**, **the way your users speak them**.

---

## ğŸ“¦ Sample File Structure

```ini
â”œâ”€â”€ custom_speech_project/
â”‚   â”œâ”€â”€ test/
â”‚   â”‚   â”œâ”€â”€ dinosaur.wav
â”‚   â”‚   â”œâ”€â”€ dinosaur_transcript.txt
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ dinosaur_words.txt
â”‚   â”‚   â”œâ”€â”€ pronunciation_map.txt
```

---

## ğŸ§° What You Need to Train a Custom Speech Model

<div style="text-align: center;">
    <img src="images/train-custom-speech-data-type.png"
         style="border-radius: 10px; width: 80%;"
         alt="Data Types for Training a Custom Speech Model">
</div>

---

| ğŸ“ Option                            | âœ… Use For...                                                               | ğŸ§  Simple Example                                                            |
| ------------------------------------ | --------------------------------------------------------------------------- | ---------------------------------------------------------------------------- |
| **Plain Text**                       | Teach the model which **important words** or **brand names** to recognize   | ğŸ“„ A text file with words like `GoDrive`, `Sharjah`, `MetroCard`, `WhatsApp` |
| **Structured Text**                  | Give the model a **list of classes/entities** using a `.cmd` format         | ğŸ§¾ Define entities like `Locations`, `Products`, `Person Names`              |
| **Audio + Human-Labeled Transcript** | Improve model by pairing **real audio** with **correct written transcript** | ğŸ¤ Audio of â€œWelcome to GoDriveâ€ + âœï¸ text: â€œWelcome to GoDriveâ€             |
| **Pronunciation**                    | Help the model recognize words with **unique pronunciation**                | ğŸ—£ï¸ People say â€œWasapâ€, but want output to show: `WhatsApp`                   |
| **Audio (Only)**                     | Just test audio quality, no transcript required                             | ğŸ§ Upload noisy or clear `.wav` files for model to practice                  |
| **Transcript (Auto Synthesized)**    | For Preview/testing only â€“ upload text, let Azure synthesize the audio      | ğŸ’¬ â€œHello from Dubaiâ€ â€“ Azure generates a voice automatically                |

---

## ğŸ§ª What You Need to Test the Speech Model

<div style="text-align: center;">
    <img src="images/test-custom-speech-data-type.png"
         style="border-radius: 10px; width: 80%;"
         alt="Data Types for Testing a Custom Speech Model">
</div>

---

| ğŸ” Test Type                               | âœ… Use It For...                                                            | ğŸ§  Example                                                                                                                           |
| ------------------------------------------ | --------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------ |
| **Inspect Quality (Audio Only)**           | Play back audio and **visually check how accurate** the transcription is    | ğŸ§ You say â€œGoDriveâ€ â†’ model outputs â€œGo dryâ€? You hear it's wrong.                                                                  |
| **Evaluate Accuracy (Audio + Transcript)** | Upload both audio and **correct transcript** to **measure word error rate** | ğŸ§ Audio: â€œIâ€™m at Sharjah Metroâ€ + ğŸ“ Transcript: â€œIâ€™m at Sharjah Metroâ€ <br> â†’ Azure compares both and tells you % errors (like 5%) |

---

## ğŸ—ï¸ How It Works (Flow Diagram)

<div align="center">

```mermaid
graph TD
    A[ğŸ§ Audio Recordings] --> B[ğŸ§  Default Speech Model]
    B --> C{âŒ Incorrect Recognition?}
    C -- Yes --> D[ğŸ“ƒ Add Custom Text/Audio]
    D --> E[ğŸ” Train Custom Model]
    E --> F[ğŸ¯ Improved Transcription Output]
    C -- No --> G[ğŸ‘ Use Default Model]
```

</div>

---

## ğŸ“¦ Step-by-Step Breakdown

### 1ï¸âƒ£ Prepare Your Data

Youâ€™ll need:

- âœ… Some **short WAV audio clips**
- âœ… Matching **text transcripts** (what the audio should say)
- âœ… (Optional) Word lists or pronunciation mappings

ğŸ“ Easy example:

- Audio: someone saying "Book ride to JLT"
- Transcript: "Book ride to JLT"
- Plain text list: `GoDrive`, `JLT`, `Burj Khalifa`, `MetroPass`

---

### 2ï¸âƒ£ Upload Your Data to Speech Studio

1. Go to: [https://speech.microsoft.com](https://speech.microsoft.com)
2. Choose your **Azure subscription + region**
3. Click **â€œCustom Speechâ€**
4. Create a new **Project**
5. Upload your:

   - ğŸ§ Audio + transcript files
   - ğŸ“ƒ Word list
   - ğŸ”¤ Pronunciation mappings (if any)

---

### 3ï¸âƒ£ Evaluate the Base Model

Azure lets you test how well the **default model** does before training.

âœ… Upload a test audio and see:

- ğŸ¤– â€œWhat the model thinks the user saidâ€
- ğŸ” â€œWhere the model makes mistakesâ€

ğŸ“Š This gives you a **baseline word error rate (WER)**.
Example: 10% of words misheard.

---

### 4ï¸âƒ£ Train the Custom Model

Now give Azure:

- Your correct data (text + audio)
- Name your model
- Click **Train**

â±ï¸ Training can take 30â€“60 minutes.

ğŸ’° It does cost money â€” budget **\$50â€“\$100 USD** for full runs. Try on free tier first if possible.

---

### 5ï¸âƒ£ Test the Trained Model

Once training is done:

- Test again using the same audio
- See if error rate has improved
- Example: From 10% â†’ down to 2% error

ğŸ‘‚ You can even see **which words are now recognized correctly** (like â€œGoDriveâ€ instead of â€œgo dryâ€).

---

### 6ï¸âƒ£ Deploy & Use in Code

When you're happy with results:

- Deploy the model (it gives you a custom endpoint)
- In your code (Python, C#, REST API), point to **your trained model**, not the default one

ğŸ“˜ Python SDK:

```python
speech_config = speechsdk.SpeechConfig(
    subscription=SPEECH_KEY,
    region=SPEECH_REGION
)
speech_config.endpoint_id = "your_custom_model_endpoint_id"
```

---

## ğŸ§  Evaluation Metrics

| Metric                   | Meaning                                           |
| ------------------------ | ------------------------------------------------- |
| âŒ Word Error Rate (WER) | How many words were wrong (in %, lower is better) |
| ğŸ§© Substitution          | Model said wrong word instead of correct one      |
| â– Deletion              | Model missed a word                               |
| â• Insertion             | Model added a word that wasnâ€™t there              |

---

## ğŸ’¬ Common Use Cases

| Industry        | Example                                            |
| --------------- | -------------------------------------------------- |
| ğŸš– Ride Hailing | Custom words like â€œGoDriveâ€, â€œSharjahâ€, â€œSalikâ€    |
| ğŸ¥ Healthcare   | Drug names, hospital terms like â€œIbuprofenâ€, â€œMRIâ€ |
| ğŸ“¦ Logistics    | Terms like â€œDock #7â€, â€œWaybillâ€, â€œLoadsheetâ€       |
| ğŸ« Education    | Course names like â€œMath 101â€, â€œIELTSâ€, â€œTOEFLâ€     |

---

## ğŸ¤– Pro Tip: Custom â‰  Always Needed

> If your base model has 99%+ accuracy â€” _donâ€™t bother training._

But if you're:

- In a niche domain ğŸ¯
- Have domain-specific terminology ğŸ§¬
- Need high precision in transcripts ğŸ“œ

Then go **Custom Speech all the way** ğŸ’ª

---

## ğŸ§ª Practice Tip for AI-102

> ğŸ’¡ Donâ€™t memorize dinosaur names.
> Create a **simple use case**, upload **3â€“5 short audio clips**, and **evaluate improvements** using Speech Studio.
> Then try to deploy your model and test via code.

---

## ğŸ“š Resources

- ğŸ”— [Azure Custom Speech Docs](https://learn.microsoft.com/en-us/azure/ai-services/speech-service/custom-speech-overview)
- ğŸ”— [Speech Studio](https://speech.microsoft.com/)
- ğŸ’¾ Dataset example:

  - `audio1.wav` â†’ "Order lunch from FoodDash"
  - Transcript: `Order lunch from FoodDash`
  - Plain Text List: `FoodDash`, `Delivery`, `Downtown`, `JLT`, `Dubai`
