# ğŸ§± Azure AI Content Safety - Blocklist Magic âœ¨

Welcome to the dark side of moderationâ€”**where you don't just detect unsafe text but teach the model what's offensive for your context.** In this topic, we explore how to customize moderation with **Text Blocklists** using Azure AI Content Safety. Let's dive deep into what blocklists are, why they exist, and how to master them with Python. Ready? Letâ€™s do this!

---

## ğŸ“– Official Definition

**Blocklists in Azure AI Content Safety** let you define custom words or phrases that should be flagged as inappropriate or harmfulâ€”even if the AI model doesnâ€™t consider them bad by default.

> "A blocklist is a user-defined list of words that Azure AI Content Safety will treat as sensitive or unsafe during text analysis."

This is crucial when you're working with **domain-specific jargon**, slang, or internal terms that you'd like to monitor or suppress.

---

## ğŸ¤” Why Blocklists Matter

By default, the Azure Content Safety model flags hate speech, sexual content, violence, and self-harm. But it may miss your team's inside jokes or secret company codenames that are actually **seriously offensive** in context.

So instead of retraining the model (hard and expensive), **you extend it with a blocklist**. ğŸ¯

---

## ğŸ§  High-Level Flow

<div align="center">

```mermaid
flowchart TD
    A[Input Text] --> B[Content Safety Service]
    B --> C{AI Default Rules}
    C -->|Match| D[Moderation Result]
    C -->|No Match| E[Check Custom Blocklists]
    E -->|Custom Match| D
    E -->|No Match| F[Text Considered Safe]
```

</div>

---

## ğŸ› ï¸ Core Use Cases (CRUD Style)

| Operation   | Description                                 |
| ----------- | ------------------------------------------- |
| **Create**  | Make a new named blocklist                  |
| **Read**    | List or get details of blocklists           |
| **Update**  | Add/update items in a blocklist             |
| **Delete**  | Remove items or delete entire blocklist     |
| **Analyze** | Use your blocklist in real content scanning |

---

## ğŸ’¡ Example Scenario

Letâ€™s say your app allows users to chat. While Azure flags default profanity, it doesn't know your team's code words like:

- `k*ll` (with a star for obfuscation)
- `h*te` (slang used in your app)

You want to **catch and moderate those**, even when users try to sneak around filters. Blocklists to the rescue!

---

## ğŸ§ª Letâ€™s Code â€“ Full CRUD Demo

Here's a full Python implementation that does:

âœ… Create blocklist
âœ… Add offensive items
âœ… Analyze input text
âœ… List and get items
âœ… Remove item
âœ… Delete blocklist

ğŸ§  **Pro Tip:** Only \~10â€“15 lines actually do the work. The rest is just setup and error handling.

### ğŸ§¬ Setup

Install the SDK:

```bash
pip install azure-ai-contentsafety
```

Then copy this Python code:

```python
# Azure AI ContentSafety Text BlockList CRUD
KEY = "f7324ffadc7e4da0b5b253230a44a849"
ENDPOINT = "https://azure-content-safety-demo-345.cognitiveservices.azure.com/"
```

---

### ğŸ§± 1. Create or Update a Blocklist

```python
from azure.ai.contentsafety import BlocklistClient
from azure.ai.contentsafety.models import TextBlocklist
from azure.core.credentials import AzureKeyCredential

client = BlocklistClient(ENDPOINT, AzureKeyCredential(KEY))

blocklist = client.create_or_update_text_blocklist(
    blocklist_name="TestBlocklist",
    options=TextBlocklist(
        blocklist_name="TestBlocklist",
        description="Test blocklist management."
    )
)
print(f"âœ… Created Blocklist: {blocklist.blocklist_name}")
```

---

### â• 2. Add Block Items

```python
from azure.ai.contentsafety.models import TextBlocklistItem, AddOrUpdateTextBlocklistItemsOptions

items = [
    TextBlocklistItem(text="k*ll"),
    TextBlocklistItem(text="h*te"),
]

result = client.add_or_update_blocklist_items(
    blocklist_name="TestBlocklist",
    options=AddOrUpdateTextBlocklistItemsOptions(blocklist_items=items),
)

for item in result.blocklist_items:
    print(f"ğŸ§© Added Block Item: {item.text} (ID: {item.blocklist_item_id})")
```

---

### ğŸ” 3. Analyze Text Using Blocklist

```python
from azure.ai.contentsafety import ContentSafetyClient
from azure.ai.contentsafety.models import AnalyzeTextOptions

safety_client = ContentSafetyClient(ENDPOINT, AzureKeyCredential(KEY))

analysis_result = safety_client.analyze_text(
    AnalyzeTextOptions(
        text="I h*te you and I want to k*ll you.",
        blocklist_names=["TestBlocklist"],
        halt_on_blocklist_hit=False
    )
)

for match in analysis_result.blocklists_match:
    print(f"ğŸš¨ Match! Word: {match.blocklist_item_text} in {match.blocklist_name}")
```

ğŸ§  **Smart Tip**: The AI understands word variationsâ€”even obfuscated ones like `k*ll`. It's not doing a plain `grep`, it actually _thinks_. ğŸ¤¯

---

### ğŸ“œ 4. List Blocklists and Items

```python
# List all blocklists
for bl in client.list_text_blocklists():
    print(f"ğŸ“š Blocklist: {bl.blocklist_name} - {bl.description}")

# List items in a blocklist
for item in client.list_text_blocklist_items(blocklist_name="TestBlocklist"):
    print(f"ğŸ§± Block Item: {item.text}")
```

---

### ğŸ” 5. Get Blocklist or Item by ID

```python
# Get blocklist
bl = client.get_text_blocklist(blocklist_name="TestBlocklist")
print(f"ğŸ¯ Retrieved Blocklist: {bl.blocklist_name}")

# Get a block item (you need the ID)
item_id = result.blocklist_items[0].blocklist_item_id
item = client.get_text_blocklist_item("TestBlocklist", blocklist_item_id=item_id)
print(f"ğŸ” Block Item Detail: {item.text} - ID: {item.blocklist_item_id}")
```

---

### âŒ 6. Remove an Item

```python
from azure.ai.contentsafety.models import RemoveTextBlocklistItemsOptions

client.remove_blocklist_items(
    blocklist_name="TestBlocklist",
    options=RemoveTextBlocklistItemsOptions(blocklist_item_ids=[item_id])
)
print(f"ğŸ—‘ï¸ Removed item ID: {item_id}")
```

---

### ğŸ’¥ 7. Delete the Blocklist

```python
client.delete_text_blocklist(blocklist_name="TestBlocklist")
print("ğŸ§¹ Blocklist deleted!")
```

---

## ğŸ§  What You Just Learned

- ğŸ§± How to create and manage text blocklists
- âœï¸ How to insert custom unsafe words
- ğŸš¨ How Azure detects both default and custom content
- ğŸ§° CRUD operations on blocklists and their items
- ğŸ§  Bonus: It's smarter than `grep`, using real ML reasoning!

---

## ğŸ§­ When to Use Blocklists

- You have **domain-specific terms** you want to moderate.
- You're dealing with **non-English dialects or slang**.
- You want to **enforce stricter standards** than what Azure provides out of the box.
- You need **auditable and maintainable custom word filters**.

---

## ğŸš€ Pro Debugging Tip

Set breakpoints only on the real action lines (e.g. `analyze_text`, `add_or_update_blocklist_items`). Ignore 80% of the boilerplateâ€”because **only a few lines do the magic**.

---

## ğŸ“Œ Final Thoughts

This feature brings power to **customize Azure AIâ€™s safety brain**. You donâ€™t need to retrain the modelâ€”you just _whisper your own red flags into its ear_.

ğŸ‘‰ Test it. Break it. Customize it. Itâ€™s your personal **AI gatekeeper** for content.

---

## ğŸ“š Docs

[Use blocklist](https://learn.microsoft.com/en-us/azure/ai-services/content-safety/how-to/use-blocklist?tabs=windows%2Ccsharp)
