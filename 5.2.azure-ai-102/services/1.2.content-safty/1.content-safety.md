# ğŸ›¡ï¸ Azure AI Content Safety â€“ Text & Image Moderation

## ğŸš€ Overview

**Azure AI Content Safety** is the upgraded and modernized version of the older "Content Moderator" service. It detects harmful, offensive, or unsafe content in **text** and **images** â€” with precision, AI flair, and some seriously powerful ML under the hood.

> âš ï¸ **Important:** The older `Content Moderator` service is deprecated. Use `Azure AI Content Safety` for all **moderation** needs across image & text content.

---

## ğŸ“š Official Definition

> Azure AI Content Safety helps organizations detect **harmful content** in both **text** and **images**. It categorizes content into **hate**, **self-harm**, **sexual**, and **violence**, providing severity scores for each.

---

## ğŸ§  Categories Detected

Content is analyzed for four critical **safety categories**, each returning a `severity` score from **0 (Safe)** to **6 (Extremely Unsafe)**.

| Category         | Description                                 |
| ---------------- | ------------------------------------------- |
| ğŸ§¨ **Hate**      | Hateful speech, slurs, racism, bigotry.     |
| âš”ï¸ **Violence**  | Threats, physical aggression, gory content. |
| ğŸ©¸ **Self-harm** | Mentions of suicide, self-injury.           |
| ğŸ‘ **Sexual**    | Nudity, explicit content, sexual language.  |

---

## ğŸ” Use Cases

| Scenario                   | Why It Matters ğŸ“¢                                             |
| -------------------------- | ------------------------------------------------------------- |
| ğŸŒ User-generated content  | Filter offensive memes or abusive messages before going live. |
| ğŸ“¸ Image uploads           | Flag NSFW or violent images on your platform.                 |
| ğŸ’¬ Chat applications       | Detect and act on harmful language in real time.              |
| ğŸ“° News or media pipelines | Moderate images and captions automatically.                   |

---

## ğŸ› ï¸ Setup Steps

1. **Go to Azure Portal**
2. Navigate to: **Azure AI Services â†’ Content Safety**
3. Click `Create`, fill in:

   - Resource Group
   - Name
   - Region
   - Pricing Tier (start with Free â˜•)

4. After deployment, copy:

   - âœ… `Endpoint`
   - âœ… `API Key`

---

## ğŸ–¼ï¸ Image Moderation Example (Python)

```bash
pip install azure-ai-contentsafety
```

```python
from azure.ai.contentsafety import ContentSafetyClient
from azure.core.credentials import AzureKeyCredential
from azure.ai.contentsafety.models import (
    AnalyzeImageOptions, ImageData, ImageCategory
)

client = ContentSafetyClient(endpoint="YOUR_ENDPOINT", credential=AzureKeyCredential("YOUR_KEY"))

with open("sample.jpg", "rb") as img:
    request = AnalyzeImageOptions(image=ImageData(content=img.read()))

response = client.analyze_image(request)

for item in response.categories_analysis:
    print(f"{item.category}: Severity {item.severity}")
```

ğŸ” **Sample Output**

```ini
HATE: Severity 0
SELF_HARM: Severity 0
SEXUAL: Severity 2
VIOLENCE: Severity 0
```

---

## ğŸ“„ Text Moderation Example (Python)

```python
from azure.ai.contentsafety.models import AnalyzeTextOptions, TextCategory

request = AnalyzeTextOptions(text="I will kill you.")

response = client.analyze_text(request)

for item in response.categories_analysis:
    print(f"{item.category}: Severity {item.severity}")
```

ğŸ§  **Insight**: It doesnâ€™t look just for keywords like "kill" â€” it **contextually understands** the sentenceâ€™s meaning. Amazing, right?

---

## ğŸ“Š Response Structure

Each call returns a structured response:

```json
{
  "categories_analysis": [
    {
      "category": "HATE",
      "severity": 0
    },
    {
      "category": "SEXUAL",
      "severity": 2
    }
  ]
}
```

- No complex probability scores.
- Just **category** + **severity**. Simple & fast.

---

## ğŸ“ˆ Sequence Flow (Mermaid Style)

<div align="center">

```mermaid
sequenceDiagram
    participant User
    participant Azure Client SDK
    participant Content Safety API
    participant Azure AI Model

    User->>Azure Client SDK: Upload image/text
    Azure Client SDK->>Content Safety API: Send request
    Content Safety API->>Azure AI Model: Analyze content
    Azure AI Model-->>Content Safety API: Return category severities
    Content Safety API-->>Azure Client SDK: JSON response
    Azure Client SDK-->>User: Print or act on response
```

</div>

---

## ğŸ§ª Testing Ideas

Try the following examples:

**Text Examples:**

- "I hate you" â†’ Should trigger `HATE`
- "I will jump from the bridge" â†’ `SELF_HARM`
- "Explicit content description" â†’ `SEXUAL`
- "Letâ€™s start a riot and burn things!" â†’ `VIOLENCE`

**Image Examples:**

- Upload peaceful landscape = Severity 0s
- Upload disturbing news image = High `VIOLENCE`
- Upload image of politician with text = Depends on content

âš ï¸ You won't see a score for "probability"â€”just a **severity level**.

---

## ğŸ¤– LLM vs Content Safety?

> Canâ€™t we use ChatGPT for moderation?

Yes, **LLMs can be prompted** for moderation, butâ€¦

| Content Safety AI           | ChatGPT with Prompts         |
| --------------------------- | ---------------------------- |
| âœ… Trained for moderation   | ğŸ§  General purpose           |
| âœ… Consistent output        | âŒ May hallucinate           |
| âœ… Real-time safety scoring | âš ï¸ Can be biased or verbose  |
| âœ… Scalable & cheap         | ğŸ’¸ Higher cost per inference |

ğŸ—£ï¸ Think of this as the **"master of one" vs "jack of all"** tradeoff.

---

## ğŸ“Œ Notes

- SDK: [`azure-ai-contentsafety`](https://pypi.org/project/azure-ai-contentsafety/)
- Docs: [Azure AI Content Safety Docs](https://learn.microsoft.com/en-us/azure/ai-services/content-safety/overview)
- Full API reference: [Text API](https://learn.microsoft.com/en-us/azure/ai-services/content-safety/how-to/text-moderation), [Image API](https://learn.microsoft.com/en-us/azure/ai-services/content-safety/how-to/image-moderation)
- Free tier includes limited usageâ€”good for testing ğŸ§ª

---

## ğŸ¯ Summary

- âœ… Azure AI Content Safety is your go-to service for **moderating image and text** using AI.
- âœ… Detects 4 categories with severity from 0 to 6.
- âœ… Python SDK is clean and production-ready.
- âœ… Ideal for web apps, community platforms, chat services, and more.

> ğŸ’¡ Pro tip: Use specific moderation models for consistency; fallback to LLMs if necessary, but never rely on them alone for compliance or risk-sensitive use cases.
