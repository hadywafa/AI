# ğŸ“š **RAG in Action: Azure Search + OpenAI Demo**

Welcome to the most production-ready Retrieval Augmented Generation (RAG) demo using Azure Search and Azure OpenAI. This hands-on example isn't just a toy projectâ€”it's enterprise-ready, scalable, and tightly integrated with Azure services. If you ever wondered how to implement RAG in the real world, this is your golden reference.

---

## ğŸ§  What Is This Demo?

This project is a complete **end-to-end RAG application** powered by:

- ğŸ§¾ **Private documents** (PDF, TXT, Word, etc.)
- ğŸ“¦ **Vector embeddings** using OpenAI embeddings API
- ğŸ§  **LLMs** via Azure OpenAI
- ğŸ” **Azure AI Search** as the vector database
- ğŸ’» **Web app** frontend + Python backend
- ğŸ”§ **Azure Developer CLI (azd)** for full deployment

âœ… It supports **multi-modal documents**, works well with **large datasets**, and helps you build **ChatGPT-like UI** for your own content.

---

## ğŸ› ï¸ Why Is It Important?

This isnâ€™t just a sample appâ€”it solves real-world LLM problems:

| Problem                              | Solution from this Demo                         |
| ------------------------------------ | ----------------------------------------------- |
| âŒ LLMs don't know your private data | âœ… RAG augments prompts with real company data  |
| âŒ Context limit (e.g., 128K tokens) | âœ… Retrieve only relevant chunk per query       |
| âŒ Hallucination risk                | âœ… Ground answers using vector-based retrieval  |
| âŒ Fine-tuning cost/effort           | âœ… No fine-tuningâ€”keep your model static + safe |

---

## ğŸ§± Architecture Breakdown

<div align="center">

```mermaid
flowchart TD
    A["User (Web UI)"] -->|Asks Question| B[Python Backend API]
    B --> C[Query Embedding Generation]
    C --> D["Azure Cognitive Search (Vector DB)"]
    D -->|Top-K Results| E[Relevant Chunks + Metadata]
    E --> F["Prompt Builder (Prompt + Context)"]
    F --> G[Azure OpenAI LLM]
    G --> H[Answer Returned to UI]
```

</div>

---

- âœ… **Embedding**: The question is embedded using OpenAIâ€™s embedding model
- âœ… **Search**: Query embedding is compared with indexed vector embeddings in Azure AI Search
- âœ… **Prompt Augmentation**: Top relevant chunks are injected into a prompt
- âœ… **LLM**: The prompt is sent to Azure OpenAIâ€™s model (e.g., GPT-35, GPT-4)
- âœ… **Answer**: Final grounded answer shown in the chat UI

---

## ğŸ“‚ Project Structure

```bash
azure-search-openai-demo/
â”œâ”€â”€ app/                  # Frontend (TypeScript / React)
â”œâ”€â”€ backend/              # Python FastAPI app (main LLM logic)
â”œâ”€â”€ data/                 # Folder for your private files (PDFs etc.)
â”œâ”€â”€ embeddings/           # Embedding & document parser logic
â”œâ”€â”€ infra/                # Bicep templates for Azure resources
â”œâ”€â”€ scripts/              # Helpers to prep docs, index them
â””â”€â”€ azure.yaml            # Main entry point for azd up
```

---

## ğŸ Step-by-Step: From Zero to RAG

### ğŸ“¥ Step 1: Clone the Repo

```bash
git clone https://github.com/Azure-Samples/azure-search-openai-demo
cd azure-search-openai-demo
```

### ğŸ”§ Step 2: Prerequisites

Install:

- Azure CLI + Bicep
- Azure Developer CLI (`azd`)
- Python 3.10+
- Node.js 18+
- VS Code (optional but useful)

Login:

```bash
azd auth login
```

### ğŸš€ Step 3: One Command Deployment

```bash
azd up
```

â± This command does **everything**:

- Provisions: Azure OpenAI, Azure AI Search, App Services, Blob Storage, Document Intelligence, Log Analytics
- Deploys: Frontend + Backend
- Uploads: Sample data from `/data/` folder
- Indexes: Converts documents into embeddings and loads into Azure Search

ğŸ§¾ Example Docs:

```bash
/data/contoso-electronics/
â”œâ”€â”€ faq.pdf
â”œâ”€â”€ company-policies.txt
â”œâ”€â”€ user-manual.docx
```

---

## ğŸ§  Behind the Scenes

### ğŸ“Œ Embedding Phase

When you upload files:

1. They are parsed using [Azure Document Intelligence](https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/overview)
2. Each text chunk (e.g., 500 tokens) is passed to OpenAI Embedding model (`text-embedding-ada-002`)
3. The resulting vectors are stored in Azure AI Search as vector fields

ğŸ“¦ This is done using this code in `backend/ingest.py`:

```python
response = openai_client.embeddings.create(input=text_chunk, model="text-embedding-ada-002")
vector = response.data[0].embedding
```

---

### ğŸ” Query Phase

When a user asks:

1. Query is embedded using the same model
2. Azure AI Search uses **vector similarity** (cosine similarity) to retrieve top-k relevant chunks
3. These chunks are combined with the query in a **custom prompt template**
4. LLM is called with that augmented prompt

âœ… **No fine-tuning needed**  
âœ… **Fully grounded on your data**  
âœ… **Prevents hallucination**

---

## ğŸ–¼ï¸ Real Chat UI Preview

You get a browser UI like ChatGPT with:

- ğŸ“ Chat interface
- ğŸ“ File source for each answer
- ğŸ” Settings: Search mode, temperature, top-k results
- âœ… Grounded answers from your own documents!

---

## ğŸ”¬ Search Modes Supported

The app supports 4 query methods:

| Mode                   | Description                                         |
| ---------------------- | --------------------------------------------------- |
| ğŸ” **Semantic Search** | Uses Azure Cognitive Search's deep meaning matching |
| ğŸ§  **Vector + Text**   | Hybrid of keyword and embedding match               |
| ğŸ” **Vector Only**     | Pure vector similarity                              |
| ğŸ§¾ **Text Only**       | Traditional keyword search                          |

Set this in UI or config.

---

## ğŸ“‰ Cost Considerations

| Resource                 | Comment                                |
| ------------------------ | -------------------------------------- |
| ğŸ’¸ Azure Search          | Most expensive (use S tier carefully)  |
| ğŸ”¤ Embeddings            | Charged per token                      |
| ğŸ’¬ OpenAI Model          | Charged per prompt + completion tokens |
| â˜ï¸ App Service           | Minor                                  |
| ğŸ“„ Document Intelligence | Cost if parsing complex docs           |

ğŸ§¼ Shut down with:

```bash
azd down
```

---

## ğŸ’¡ Examples

### ğŸ—‚ï¸ Example 1: Query From Private PDF

- You upload `employee-handbook.pdf`
- User asks: _"What is the policy for medical leave?"_
- RAG extracts only that section
- Prompt is:

```text
Context:
<Medical Leave policy chunk>

Question:
What is the policy for medical leave?
```

- LLM responds with the exact answer, citing the PDF!

---

### ğŸ§ª Example 2: Grounded Chat With Multiple Sources

Uploaded:

- `faq.pdf`
- `training-guide.txt`

Query:

> â€œWhatâ€™s the process for setting up new IoT devices?â€

Response:

- Combines relevant paragraphs from both docs
- Shows references below the answer
- Prevents hallucinating instructions

---

## âš ï¸ Known Gotchas

| Problem                          | Fix                             |
| -------------------------------- | ------------------------------- |
| ğŸ” Old .md5 files not cleaned    | Manually delete `/data/*.md5`   |
| ğŸ§  Embedding not triggered       | `azd down` then `azd up` again  |
| â›”ï¸ â€œI don't knowâ€ response      | Means no chunk passed threshold |
| ğŸ’¸ Cost spikes from Azure Search | Use Free or Basic SKU for dev   |

---

## ğŸ” Security & Governance

âœ… Your data is:

- Stored in Azure Blob Storage
- Indexed securely via Azure AI Search
- Embedded using OpenAI embedding model (no fine-tuning)
- Never sent to model hosts unless you explicitly call it

ğŸ”’ Enable:

- Private networking (VNET + Private Link)
- Role-based access (RBAC)
- Logging & alerting via Azure Monitor

---

## ğŸ§µ Summary: Why This RAG Demo Rocks

| Feature              | Value                          |
| -------------------- | ------------------------------ |
| ğŸ”§ Turnkey Setup     | Deploy with `azd up`           |
| ğŸ§  Custom Knowledge  | Works with your PDFs, docs     |
| ğŸ” Smart Retrieval   | Vector + semantic ranking      |
| ğŸ“± Beautiful UI      | ChatGPT-style interface        |
| ğŸ”’ Secure & Scalable | Azure-native, enterprise-ready |
