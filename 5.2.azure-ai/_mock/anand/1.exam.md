# Exam 1

## ❌ Question 6

![ex1_q6](images/ex1_q6.png)

---

**✅ The answer:**
`1. https://centralus.api.cognitive.microsoft.com`
`2. /text/analytics/v3.1/languages`

---

**🤔 Why This Is the Best Answer:**

- `https://centralus.api.cognitive.microsoft.com`: This is a valid **base endpoint** for Azure Cognitive Services in the **Central US region**, commonly used for services like Text Analytics (Language Detection).
- `/text/analytics/v3.1/languages`: This is the correct **API path** for detecting the language of a given input using the **Azure AI Language** service. It helps you determine whether a customer query is in English or Spanish so you can route it accordingly.

---

**❌ Why Other Options Are Wrong:**

- `https://eu.api.cognitive.microsofttranslator.com`: While valid for Translator, it doesn't relate to **language detection**; it's just a **regional base URL**.
- `/translator/text/v3.0/translate?to=es` and `/translate?to=en`: These are **translation endpoints**, not for detecting language. Translation is **not required** in this use case since the goal is routing based on **original message language**, not converting it.
- `https://portal.azure.com`: This is just the **web portal**, not an API endpoint. It cannot be used in code to detect or translate language.

---

## ❌ Question 12

![ex1_q12](images/ex1_q12.png)

---

**✅ The answer:**

- **A. Use the Language Studio's performance dashboard to view metrics and evaluation reports.**
- **C. Retrieve the evaluation report from the authoring API provided by the language service.**

---

**🤔 Why This Is the Best Answer:**
These two methods directly support **pre-deployment evaluation**:

- ✅ **A. Language Studio’s performance dashboard** gives you an interactive view of how your model performs on test data — showing **metrics like precision, recall, F1 score**, confusion matrices, and misclassified utterances.

- ✅ **C. Authoring API for evaluation summary** allows you to **retrieve detailed evaluation reports** via REST. You can use this in automation or integrate it into your CI/CD pipeline.

Example API:

```http
GET https://{endpoint}/language/authoring/analyze-conversations/projects/{projectName}/models/{trainedModelLabel}/evaluation/summary-result?api-version=2023-04-01
```

---

**❌ Why Other Options Are Wrong:**

- ❌ **B. Enable feedback collection...**
  Feedback collection is part of a **post-deployment** improvement loop. It relies on **live user interaction logs** and does **not help in pre-deployment** evaluation.

- ❌ **D. Azure Monitor**
  Azure Monitor is used for **infrastructure and service health**, not for evaluating the **model's linguistic understanding**. It tracks **performance metrics like latency and availability**, not NLP accuracy.

---

📘 **Key Concept (AI-102):**

> **Pre-deployment evaluation** should be done using test datasets, evaluation reports, and built-in performance dashboards — **not production feedback or monitoring tools**.

---

## ❌ Question 15

![ex1_q15](images/ex1_q15.png)

---

**✅ The answer:**

- **A. to=el**
- **C. toScript=Latn**
- **E. textType=html**

---

**🤔 Why This Is the Best Answer:**

- ✅ **A. `to=el`** – This sets the **target language to Greek**, which is the main translation objective. `"el"` is the correct ISO language code for Greek.

- ✅ **C. `toScript=Latn`** – This enables **Roman (Latin script) transliteration** of the translated Greek text. Greek normally uses the Greek script, so `toScript=Latn` provides a phonetic version readable by non-Greek users.

- ✅ **E. `textType=html`** – This indicates the input is **HTML content**, so the API treats tags appropriately and doesn’t translate elements like `<div>` or `<strong>`. This is important for product descriptions that may contain formatting.

---

**❌ Why Other Options Are Wrong:**

- ❌ **B. `from=fr`** – This is only useful if the source text is explicitly in French. Since source detection is automatic by default and the question doesn’t mention French, this is unnecessary.

- ❌ **D. `textType=xml`** – This is not correct for standard product description text. Unless you're passing actual XML documents, `textType=html` is more appropriate.

- ❌ **F. `toScript=Cyrl`** – `Cyrl` is Cyrillic script (used in Russian, Serbian, etc.), which is **not appropriate for Greek**. Greek uses its own script and transliterates to **Latin (Latn)**, not Cyrillic.

---

## ❌ Question 16

![ex1_q16](images/ex1_q16.png)

---

**✅ The answer:**
**(A) 1, 4 — `StorageConnectionString`, `Objects`**

---

**🤔 Why This Is the Best Answer:**
To build a functional **Knowledge Store** in Azure AI Search that supports **enriched data like Sentiment Analysis**, you need to define:

- ✅ **`StorageConnectionString`** – This is **mandatory** to connect your Knowledge Store to an **Azure Storage account** where enriched data (tables, objects) will be saved.
- ✅ **`Objects`** – This defines **projection formats** such as enriched JSON documents. Objects are used when you want to store complete enriched documents (e.g., customer review + sentiment + key phrases) for flexible retrieval or further processing.

These two together allow:

- Saving enriched results in a structured but flexible way.
- Retrieving entire enriched documents (great for dashboards, analytics, or full reviews).

---

**❌ Why Other Options Are Wrong:**

- ❌ **`Tables`** – While valid, it’s optional and only needed when you want **normalized/tabular projections** (like splitting key phrases or entities into separate rows). It’s not the best **default** if you want flexible, full-document access.

- ❌ **`ContainerName`** – This is **not a valid field** in the `knowledgeStore` definition block. Azure uses the storage connection string to resolve the correct container or blob context.

- ❌ **C) 1, 2 (`StorageConnectionString`, `Tables`)** – Close, but not ideal for **flexible access**. Tables are great for relational processing, not for retrieving the entire enriched review.

- ❌ **B) 3, 2 (`ContainerName`, `Tables`)** – Incorrect. `ContainerName` is not used in Knowledge Store definitions. Plus, it omits the required `StorageConnectionString`.

---

📦 **Correct Knowledge Store JSON (simplified):**

```json
"knowledgeStore": {
  "storageConnectionString": "<your-azure-blob-connection-string>",
  "projections": [
    {
      "objects": [
        {
          "source": "/document",
          "storageContainer": "enriched-reviews"
        }
      ]
    }
  ]
}
```

---

## ✅ Question 20

![ex1_q20](images/ex1_q20.png)

**✅ The answer:**
**C) Change Domains to General (compact) → Retrain the model → Export the model**

---

**🤔 Why This Is the Best Answer:**
To export a model for **offline or edge deployment**, Azure Custom Vision requires that you use a **Compact domain** (like _General (compact)_), which supports model export in ONNX, TensorFlow, or other embedded formats.

Here’s why each step is necessary:

1. ✅ **Change Domains to General (compact):**

   - Only **Compact domains** support **exporting models**. The standard "General" domain does **not support export**.

2. ✅ **Retrain the model:**

   - After changing the domain, you **must retrain** the model — Custom Vision models are tied to a specific domain during training.

3. ✅ **Export the model:**

   - Once retrained with a compact domain, the **export button becomes available**, allowing you to download the model in formats like ONNX or TensorFlow Lite for use on devices without internet access.

---

**❌ Why Other Options Are Wrong:**

- ❌ **A. Optimize model for edge deployment** – There’s no separate "optimize" step in Custom Vision. The optimization happens automatically when you **train using a compact domain**.

- ❌ **B. Retrain the model** (first) – Retraining before switching to a compact domain is **pointless**, because only compact domains allow exports. You’d have to retrain again anyway after switching.

- ❌ **D. Change the classification type** – This isn’t related to exportability. It determines **how labels are assigned** (multiclass vs. multilabel), not deployment compatibility.

- ❌ **E. Create a new classification model** – You can reuse the existing project by just changing its domain and retraining. Creating a new model isn’t necessary unless you want to start from scratch.

---

🛠️ **Pro Tip:**
For exporting a model to work on disconnected or embedded environments like Raspberry Pi, microcontrollers, or industrial devices, **always use Compact domains** in Custom Vision.

---

📘 **Final Workflow:**
👉 **Change to General (compact)** → 🔁 **Retrain the model** → ⬇️ **Export the model for offline use**.
