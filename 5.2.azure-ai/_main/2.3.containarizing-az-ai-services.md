# ğŸ³ Running Azure AI Services in Containers â€“ Ultimate Guide

> Run Azure AI anywhere â€” in your Kubernetes cluster, Docker on-prem, or air-gapped server, with full control over **data**, **scale**, and **billing**.

---

<div style="text-align: center;">
    <img src="images/az-ai-containers.png"
         style="border-radius: 10px; width: 90%;"
         alt="az-ai-containers">
</div>

## ğŸ“¦ Why Run Azure AI in Containers?

| Feature                       | Description                                          |
| ----------------------------- | ---------------------------------------------------- |
| **Deployment Options**        | Run in Docker, AKS, ACI, or even offline             |
| **Data Control**              | All data is processed locally, stays on your network |
| **Scalability & Flexibility** | Use containers in any environment, scale as needed   |

ğŸŒŸ Ideal for: Regulated industries, private data, hybrid cloud, or disconnected edge environments.

---

## ğŸ› ï¸ Architecture â€“ How Containerized Azure AI Works

<div style="text-align: center;">
    <img src="images/az-ai-containers-workflow.png"
         style="border-radius: 10px; width: 90%;"
         alt="az-ai-containers-workflow">
</div>

---

```mermaid
sequenceDiagram
    participant ContainerRegistry
    participant ContainerHost
    participant UserApp
    participant AzureCloud

    ContainerHost->>ContainerRegistry: Pull container image (mcr.microsoft.com/azure-cognitive-services)
    UserApp->>ContainerHost: Send request (e.g. analyze text)
    ContainerHost->>UserApp: Respond with results
    ContainerHost->>AzureCloud: Report usage metrics (billing only)
```

---

> âœ… Only the **metrics for billing** are sent to Azure `periodically`.  
> âœ… Your **data never leaves your container**.

---

## ğŸ§ª Step-by-Step: Run Azure AI in a Container

### ğŸ”¹ Step 1: Get Container Image

Use [Microsoft Container Registry (MCR)](https://mcr.microsoft.com/) to pull the AI service container, for example:

```bash
docker pull mcr.microsoft.com/azure-cognitive-services/textanalytics
```

### ğŸ”¹ Step 2: Create Azure AI Resource (for licensing)

You still need to create an Azure resource like â€œLanguageâ€ or â€œVisionâ€ in the portal. This enables:

- Billing
- Licensing
- API key for local container

### ğŸ”¹ Step 3: Run the Container

```bash
docker run -it -p 5000:5000 \
  -e EULA=accept \
  -e API_KEY=your-azure-key \
  -e BILLING=https://<your-resource-name>.cognitiveservices.azure.com/ \
  mcr.microsoft.com/azure-cognitive-services/textanalytics
```

### ğŸ”¹ Step 4: Call the Local Endpoint

```bash
curl http://localhost:5000/text/analytics/v3.0/entities/recognition/general \
  -H "Content-Type: application/json" \
  -d '{"documents":[{"id":"1","language":"en","text":"Microsoft was founded by Bill Gates."}]}'
```

---

## ğŸ’° How Billing Works in Containers

> Even when running locally, billing happens through Azure based on usage **telemetry** sent to Azure from the container.

### ğŸ“Œ Billing Rules:

- Each request is **counted locally**, but **reported to Azure**.
- Azure AI resource acts like a meter ğŸ§¾.
- If you disconnect from the internet, telemetry is **buffered** (short term), then **fails**.

---

## ğŸ¤– FAQ â€“ You Asked, I Answered

### â“1. Is Swagger (OpenAPI) Supported?

âœ… **YES**
Most Azure AI containers expose:

- **Swagger UI** at `http://localhost:5000/swagger`
- **OpenAPI specs** for testing and integration

Use it for:

- Testing endpoints
- Understanding supported parameters
- Generating SDK clients

---

### â“2. If I call `localhost:5000/status`, will it go to Azure?

ğŸš« **NOPE!**
`localhost:5000` is handled **completely by your local container**. The request:

- Stays on your machine
- Does not touch Azure at all
- Is safe, fast, and local

---

### â“3. What if I run the container and disconnect from the internet?

ğŸ”Œ **It may work temporarily**, but there are caveats.

| Scenario                           | Behavior                                                                              |
| ---------------------------------- | ------------------------------------------------------------------------------------- |
| â± Short-term offline (few minutes) | Works fine, container buffers metrics                                                 |
| âŒ Long offline (hours/days)       | Container will **refuse requests** after failing to report usage                      |
| ğŸ“‰ Billing impact                  | Azure doesnâ€™t bill for requests it canâ€™t see â€” so **service stops** until reconnected |

> â˜ï¸ Azure AI container must **check in** periodically to keep working. It's like a licensing ping. No ping = no party.

---

## âœ… Summary â€“ Containerized Azure AI

| Feature                        | Works in Containers?                |
| ------------------------------ | ----------------------------------- |
| Fully local data processing    | âœ… Yes                              |
| Internet required for billing? | âœ… Yes (periodic ping)              |
| Swagger / OpenAPI              | âœ… Yes (`/swagger`)                 |
| Supports Docker, AKS, ACI      | âœ… Yes                              |
| Can run fully offline forever  | âŒ No (must call Azure for billing) |

---

## ğŸ” Pro Tips

- ğŸ§ª Test containers with `--network=none` to simulate offline use
- ğŸ” Monitor metrics using logs inside the container (`/status`, `/metrics`)
- ğŸ›‘ Throttle limits and licensing are still enforced by Azure cloud

---

## ğŸ§  Final Thought

Running Azure AI in containers = total control over **data + scale**, but you still need to stay connected enough for Azure to say â€œcool, hereâ€™s your licenseâ€ ğŸ˜„
