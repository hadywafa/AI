# ğŸ¤– Automated Evaluations in Azure AI Foundry

> Let Azure do the heavy lifting of evaluating your AI models!

---

![ai-foundry-automatic-evaluation](images/ai-foundry-automatic-evaluation.png)

---

## ğŸš€ What Are Automated Evaluations?

Automated evaluations let **Azure AI Foundry automatically check**:

- How **good** your modelâ€™s responses are ğŸ’¬
- How **safe** the content is from risks ğŸš«

These evaluations can be applied to:

- Models
- Datasets
- Prompt flows

No need for human feedback here â€” just use **AI models to test other AI models**!

---

## ğŸ“¦ Step 1: Prepare Evaluation Data

You need a dataset with:

- âœ… Prompts (example user questions)
- âœ… Responses (what the model said)
- (Optional) ğŸŸ¨ **Ground truth** answers â€” what you expected ideally

### ğŸ§  How to create this?

A fast way is:

1. Use an AI model to **auto-generate** realistic prompts and responses.
2. Manually tweak them if needed.
3. Use that as your test dataset!

ğŸ“¸ _Imagine: You generate a Q\&A about travel destinations. Then test a different model to see if it gives better answers._

---

## ğŸ“ Step 2: Choose Evaluation Metrics

When setting up automated evaluation, you select:

- **What to test** (quality, safety)
- **Which metrics to use** (AI-based or standard NLP)

Letâ€™s break them down ğŸ‘‡

---

### ğŸ“Š AI Quality Metrics

These check **how good** the answers are â€” with or without ground truth.

| Metric                         | What it checks                      | Example                                                     |
| ------------------------------ | ----------------------------------- | ----------------------------------------------------------- |
| **Coherence**                  | Does the answer make logical sense? | Is it easy to follow?                                       |
| **Relevance**                  | Is it related to the user question? | If the user asked about Paris, is it answering about Paris? |
| **F1 / BLEU / ROUGE / METEOR** | Match with ground truth             | Useful if you have expected answers                         |

> Example: You expected â€œParis is great for culture,â€ and the model said â€œParis is famous for art and museumsâ€ â†’ High overlap.

---

### ğŸ›¡ï¸ Risk & Safety Metrics

These detect **unsafe or harmful content** in model outputs.

| Risk Type    | Description                         |
| ------------ | ----------------------------------- |
| â˜ ï¸ Violence  | Mentions of physical harm or threat |
| ğŸ’¬ Hate      | Offensive or hateful speech         |
| ğŸ” Sexual    | Inappropriate or explicit content   |
| âš ï¸ Self-harm | Mentions of suicide or self-injury  |

> Azure flags such responses automatically, so you can review or block them.

---

## ğŸ” When to Use Automated Evaluations?

| Phase          | Use case                                                      |
| -------------- | ------------------------------------------------------------- |
| ğŸ”¬ Development | Test multiple prompt styles or models automatically           |
| ğŸ§ª Testing     | Compare new versions of your model before going live          |
| ğŸš€ Production  | Monitor content safety in live interactions (optional audits) |

---

## ğŸ“ Summary

| Step                 | What You Do                                   |
| -------------------- | --------------------------------------------- |
| 1ï¸âƒ£ Prepare dataset   | Prompts + responses (+ ground truth optional) |
| 2ï¸âƒ£ Generate prompts  | Use AI or app output                          |
| 3ï¸âƒ£ Choose evaluators | Quality or Safety checks                      |
| 4ï¸âƒ£ View results      | Understand where to improve your model        |
