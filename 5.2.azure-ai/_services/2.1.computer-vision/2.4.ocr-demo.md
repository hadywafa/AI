# ğŸ§¾ **Azure Computer Vision OCR â€“ Read Printed and Handwritten Text (Image to Text)**

Azureâ€™s `Read API` (under the **Computer Vision** service) uses advanced OCR (Optical Character Recognition) to extract **printed** and **handwritten** text from images â€” including photos, scanned documents, handwriting, and even whiteboard content.

---

## ğŸ§  Whatâ€™s Special About the Read API?

Unlike older OCR models (e.g., `ocr()` method), the **Read API** is:

- âœ… More accurate
- ğŸŒ Works with images from **URLs or local files**
- âœï¸ Supports **handwriting**, cursive, and multiple languages
- ğŸ”„ Returns results asynchronously (so we poll until results are ready)

---

## ğŸ” Step 1: Authentication and Setup

We first authenticate with Azure using a Computer Vision **endpoint** and **key** from your Cognitive Services resource.

```python
from azure.cognitiveservices.vision.computervision import ComputerVisionClient
from msrest.authentication import CognitiveServicesCredentials
import os

AZURE_VISION_ENDPOINT = os.getenv("AZURE_VISION_ENDPOINT")
AZURE_VISION_KEY = os.getenv("AZURE_VISION_KEY")

computervision_client = ComputerVisionClient(
    AZURE_VISION_ENDPOINT,
    CognitiveServicesCredentials(AZURE_VISION_KEY)
)
```

âœ… `os.getenv()` helps load credentials from `.env` file (safer than hardcoding).

---

## ğŸ“¸ Step 2: OCR from a Remote Image (URL)

```python
read_image_url = "https://learn.microsoft.com/azure/ai-services/computer-vision/media/quickstarts/presentation.png"
read_response = computervision_client.read(read_image_url, raw=True)
```

- We pass an **image URL** to `read()`
- `raw=True` is needed to access response headers
- Response header includes an **Operation-Location URL** â€” used to track async result status

### ğŸ” Polling for Results

```python
operation_id = read_response.headers["Operation-Location"].split("/")[-1]

while True:
    read_result = computervision_client.get_read_result(operation_id)
    if read_result.status not in ["notStarted", "running"]:
        break
    time.sleep(1)
```

- We extract the **operation ID**
- We call `get_read_result()` in a loop until status is `succeeded` or `failed`
- `sleep(1)` prevents hammering the API too fast

---

## ğŸ“¤ Step 3: Parsing the OCR Result

```python
if read_result.status == OperationStatusCodes.succeeded:
    for text_result in read_result.analyze_result.read_results:
        for line in text_result.lines:
            print(line.text)
            print(line.bounding_box)
```

Each line object includes:

- ğŸ§¾ `text`: actual line of text
- ğŸ“ `bounding_box`: coordinates of the text in the image, as a list of 8 numbers (4 points)

ğŸ§  Example Output:

```ini
Azure Cognitive Services
[100, 75, 580, 75, 580, 130, 100, 130]
```

---

### ğŸ“‚ Step 4: OCR from Local Image

Now letâ€™s process an image stored locally, such as a **handwritten note** or **scanned receipt**.

```python
local_image = open("./Handwritten_Notes/note.jpg", "rb")
read_response = computervision_client.read_in_stream(local_image, raw=True)
```

- `read_in_stream()` reads image from binary stream (`open(..., "rb")`)
- The rest is **identical** to the remote example: extract operation ID, poll, and parse

---

## ğŸ¯ Summary of Key Methods

| Method                          | Use Case                          |
| ------------------------------- | --------------------------------- |
| `read(url)`                     | OCR for remote images via URL     |
| `read_in_stream(image)`         | OCR for local image files         |
| `get_read_result(operation_id)` | Polls until OCR results are ready |

---

## ğŸ’¡ Real-World Use Cases

| Use Case                     | Benefit                            |
| ---------------------------- | ---------------------------------- |
| Digitizing scanned invoices  | Turn printed text into usable data |
| Processing handwritten forms | Extract cursive notes digitally    |
| Reading signboards in images | Great for accessibility + indexing |
| Analyzing whiteboards        | Store and search meeting content   |

---

## ğŸ§ª Bonus Tips

- âœ… Use high-resolution, well-lit images
- ğŸ’¬ Use OCR with **language hints** for better multilingual support
- ğŸ§¾ Combine with Azure Form Recognizer if layout matters (tables, forms)
