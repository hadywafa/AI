# üë§ Detect, Analyze, and Recognize Faces with Azure AI Vision

Face detection and analysis are common computer vision tasks used in **security**, **personalization**, and **human-computer interaction** systems. With **Azure AI Vision Face API**, you can build intelligent applications that:

- Detect human faces in images üì∏
- Analyze facial features and attributes üéØ
- Recognize individuals across images üß†
- Support liveness and anti-spoofing üîê

---

## üß≠ What You'll Learn

- Provision and connect to the Face API
- Detect and analyze face attributes
- Compare or verify detected faces
- Train and use a facial recognition model

> ‚ö†Ô∏è **Note:** Access to certain Face API features is restricted due to [Microsoft's Responsible AI Standards](https://learn.microsoft.com/en-us/legal/cognitive-services/face-api/access-and-data-usage). This guide focuses on **unrestricted capabilities**.

---

## üß† Face API Capabilities Overview

<div align="center">
<img src="images/faces-analysis-features.png"
         style="border-radius: 10px; width: 40%;"
         alt="Face Analysis Features">

---

| Capability                     | Description                                                  |
| ------------------------------ | ------------------------------------------------------------ |
| üßç‚Äç‚ôÇÔ∏è **Face Detection**          | Locate faces and get bounding boxes                          |
| üìê **Face Attribute Analysis** | Head pose, occlusion, glasses, blur, mask, lighting, etc.    |
| üìç **Facial Landmarks**        | Key points like pupils, eye corners, mouth corners           |
| üÜî **Face Comparison**         | Check similarity between faces in two images                 |
| ‚úÖ **Face Verification**       | Verify whether two faces belong to the same person           |
| üßë‚Äçü§ù‚Äçüßë **Face Identification**     | Identify individuals using a trained model (Person Groups)   |
| üïµÔ∏è‚Äç‚ôÇÔ∏è **Face Liveness**           | Detect if the video feed is real vs. spoofed (anti-spoofing) |

</div>

---

## üß± Provisioning the Face API

You can provision Face as:

| Resource Type              | Description                                                 |
| -------------------------- | ----------------------------------------------------------- |
| üß© **Azure AI Services**   | Multi-service endpoint (Face, Vision, Language, etc.)       |
| üèóÔ∏è **Azure AI Foundry**    | Includes multi-service resource + Prompt Flow, Agents, etc. |
| üî¨ **Standalone Face API** | Dedicated resource for face detection + free tier           |

Once provisioned, you'll get:

- ‚úÖ Endpoint: `https://<your-resource>.cognitiveservices.azure.com/`
- üîë Key for key-based authentication or
- ü™™ Token for Entra ID (formerly Azure AD) authentication

---

## üîé Detect and Analyze Faces

### üì¶ Python SDK Example

```python
from azure.ai.vision.face import FaceClient
from azure.ai.vision.face.models import *
from azure.core.credentials import AzureKeyCredential

face_client = FaceClient(
    endpoint="https://<your-resource>.cognitiveservices.azure.com/",
    credential=AzureKeyCredential("<your-key>")
)

features = [
    FaceAttributeTypeDetection01.HEAD_POSE,
    FaceAttributeTypeDetection01.OCCLUSION,
    FaceAttributeTypeDetection01.ACCESSORIES
]

with open("person.jpg", "rb") as image_data:
    result = face_client.detect(
        image_content=image_data.read(),
        detection_model=FaceDetectionModel.DETECTION01,
        recognition_model=FaceRecognitionModel.RECOGNITION01,
        return_face_id=True,
        return_face_attributes=features,
    )

for face in result:
    print("Head Pose:", face.face_attributes.head_pose)
    print("Accessories:", face.face_attributes.accessories)
```

---

### üß™ Bash / REST API (Using cURL)

```bash
curl -X POST "https://<resource>.cognitiveservices.azure.com/face/v1.0/detect?returnFaceId=true&returnFaceAttributes=headPose,occlusion,accessories&recognitionModel=recognition_01&detectionModel=detection_01" \
  -H "Ocp-Apim-Subscription-Key: <YOUR_KEY>" \
  -H "Content-Type: application/octet-stream" \
  --data-binary "@person.jpg"
```

‚úÖ Returns face metadata including pose, occlusion, and face ID.

---

### üíª C# SDK Example

```csharp
using Azure.AI.Vision.Face;
using Azure;

var faceClient = new FaceClient(
    new Uri("https://<your-resource>.cognitiveservices.azure.com/"),
    new AzureKeyCredential("<your-key>")
);

var options = new DetectFaceOptions
{
    ReturnFaceAttributes = {
        FaceAttributeTypeDetection01.HeadPose,
        FaceAttributeTypeDetection01.Occlusion,
        FaceAttributeTypeDetection01.Accessories
    },
    RecognitionModel = FaceRecognitionModel.Recognition01,
    DetectionModel = FaceDetectionModel.Detection01,
    ReturnFaceId = true
};

using var image = File.OpenRead("person.jpg");

var faces = await faceClient.DetectAsync(image, options);

foreach (var face in faces)
{
    Console.WriteLine($"Pitch: {face.FaceAttributes.HeadPose.Pitch}");
}
```

---

## üìÑ Sample JSON Response (Face Attributes)

```json
[
  {
    "faceRectangle": { "top": 174, "left": 247, "width": 246, "height": 246 },
    "faceAttributes": {
      "headPose": { "pitch": 3.7, "roll": -7.7, "yaw": -20.9 },
      "accessories": [{ "type": "glasses", "confidence": 1.0 }],
      "occlusion": {
        "foreheadOccluded": false,
        "eyeOccluded": false,
        "mouthOccluded": false
      }
    }
  }
]
```

---

## ‚úÖ Verifying Faces

Each detected face gets a **temporary face ID** (valid for 24 hours).
You can compare it to another face ID:

---

<div style="text-align: center;">
    <img src="images/faces-face-id.png" alt="Face Id" style="border-radius: 10px; width: 60%;">
</div>

---

### üîÑ Use Case: "Is this the same person in two photos?"

- Use `verify(faceId1, faceId2)`
- Doesn't require identity ‚Äî compares **facial features only**

### üß† Example Scenario:

üîí **Entry-exit verification in secure buildings**
üì∑ Compare entrance photo to exit photo
üßæ Ensure only authorized faces exit the area

---

## üßë‚Äçüíº Identifying Faces

To **persistently recognize known individuals**, follow this process:

### üèóÔ∏è Training a Person Group

1. **Create Person Group**
   (e.g., `employees` or `authorized_staff`)
2. **Add Person** to group
   Each person gets a unique `personId`
3. **Add multiple face images** per person
   (Different angles and lighting recommended)
4. **Train the group**

### ‚úÖ What You Can Do After Training:

| Task                        | API Feature                |
| --------------------------- | -------------------------- |
| Identify face from an image | `identify()`               |
| Verify against known person | `verify(faceId, personId)` |
| Match similar face          | `findSimilar()`            |

> üß† Persisted faces do not expire like `detect()` face IDs.

---

## üß† Summary

| Task                      | Method                      | Notes                                        |
| ------------------------- | --------------------------- | -------------------------------------------- |
| Detect faces + attributes | `detect()`                  | Requires `FaceAttributeTypeDetection01` list |
| Compare 2 faces           | `verify(faceId1, faceId2)`  | No need for person group                     |
| Identify person in photo  | `identify()` after training | Needs person group + persisted faces         |
| Face ID lifespan          | `24 hours` (for detect)     | `‚àû` when added to person group               |

---

## ‚úÖ Real-World Use Cases

| Use Case                                | API Feature                    |
| --------------------------------------- | ------------------------------ |
| Time tracking with photo login          | `detect()` + `identify()`      |
| Entry-exit verification in secure zones | `verify(faceId1, faceId2)`     |
| Emotion analysis in surveys             | `returnFaceAttributes=emotion` |
| Anti-spoofing in online exams           | `liveness detection`           |
