# ğŸ§¾ Read Text with Azure AI Vision Image Analysis

**Azure AI Vision** includes advanced image analysis capabilities, including **optical character recognition (OCR)** to extract readable text from images. You can use it via **REST API**, **Python**, or **.NET SDK**.

---

## ğŸ—ï¸ Provisioning the Right Resource

To use Azure AI Vision OCR capabilities, you must provision **one** of the following resources:

| Resource Type                     | Description                                                                |
| --------------------------------- | -------------------------------------------------------------------------- |
| ğŸŒ **Multi-Service Resource**     | Provides access to all Azure AI APIs (Vision, Language, etc.) under 1 key. |
| ğŸ§± **Azure AI Foundry Project**   | Includes a multi-service resource + team tools for GenAI & workflows.      |
| ğŸ–¼ï¸ **Standalone Vision Resource** | Just the Vision API; includes **free tier** (F0) for testing OCR.          |

Once provisioned, youâ€™ll receive:

- âœ… An **endpoint** like: `https://<resource-name>.cognitiveservices.azure.com/`
- âœ… An **authorization key** or ability to use **Microsoft Entra ID**

---

## ğŸ” Authentication Options

| Method                   | Description                                             | Best For              |
| ------------------------ | ------------------------------------------------------- | --------------------- |
| ğŸ”‘ **Key-based auth**    | Pass `Ocp-Apim-Subscription-Key` in headers             | Development & testing |
| ğŸªª **Microsoft Entra ID** | Token-based secure identity for enterprise applications | Production & security |

> ğŸ’¡ **Foundry SDK** users can securely fetch connection info from the Foundry project.

---

## ğŸ–¼ï¸ OCR via Image Analysis API

You can extract text using the **Image Analysis API** by passing either an image URL or binary data (JPEG, PNG, GIF, BMP).

---

## ğŸŒ 1. REST API Example (cURL)

```bash
curl -X POST "https://<resource>.cognitiveservices.azure.com/computervision/imageanalysis:analyze?api-version=2023-10-01&features=read&language=en" \
  -H "Ocp-Apim-Subscription-Key: <YOUR_KEY>" \
  -H "Content-Type: application/json" \
  --data '{
    "url": "https://aka.ms/azure-vision-sample"
  }'
```

âœ… **Features:**

- `features=read` â†’ Tells API to perform OCR
- `language=en` â†’ Optional, default is English

---

## ğŸ 2. Python SDK Example

Install the SDK:

```bash
pip install azure-ai-vision-imageanalysis
```

```python
from azure.ai.vision.imageanalysis import ImageAnalysisClient
from azure.ai.vision.imageanalysis.models import VisualFeatures
from azure.core.credentials import AzureKeyCredential

client = ImageAnalysisClient(
    endpoint="https://<resource>.cognitiveservices.azure.com/",
    credential=AzureKeyCredential("<your-key>")
)

with open("document.jpg", "rb") as img:
    image_bytes = img.read()

result = client.analyze(
    image_data=image_bytes,
    visual_features=[VisualFeatures.READ],
    language="en"
)

# Print full lines
for line in result.read_result.content.lines:
    print("Text:", line.text)
```

> ğŸ§  Use `.analyze_from_url()` if you're analyzing a web image instead of binary data.

---

## ğŸ’» 3. .NET SDK Example (C#)

Install the package:

```bash
dotnet add package Azure.AI.Vision.ImageAnalysis
```

```csharp
using Azure;
using Azure.AI.Vision.ImageAnalysis;
using System.IO;

var client = new ImageAnalysisClient(
    new Uri("https://<resource>.cognitiveservices.azure.com/"),
    new AzureKeyCredential("<your-key>")
);

using var imageStream = File.OpenRead("document.jpg");

var result = await client.AnalyzeAsync(new ImageAnalysisOptions
{
    Image = BinaryData.FromStream(imageStream),
    Features = { VisualFeature.Read },
    Language = "en"
});

foreach (var line in result.ReadResult.Content.Lines)
{
    Console.WriteLine($"Text: {line.Text}");
}
```

---

## ğŸ“¦ Sample JSON Response (OCR Output)

```json
{
  "metadata": {
    "width": 500,
    "height": 430
  },
  "readResult": {
    "blocks": [
      {
        "lines": [
          {
            "text": "Hello World!",
            "boundingPolygon": [
              {"x":251,"y":265},{"x":673,"y":260},{"x":674,"y":308},{"x":252,"y":318}
            ],
            "words": [
              {
                "text": "Hello",
                "boundingPolygon": [...],
                "confidence": 0.996
              },
              {
                "text": "World!",
                "boundingPolygon": [...],
                "confidence": 0.990
              }
            ]
          }
        ]
      }
    ]
  }
}
```

| Level        | Field              | Purpose                              |
| ------------ | ------------------ | ------------------------------------ |
| `blocks`     | High-level groups  | Currently always 1 block             |
| `lines`      | Text lines         | Full phrases from the image          |
| `words`      | Words in each line | Useful for bounding boxes or spacing |
| `confidence` | Accuracy score     | Ranges from 0 to 1 (higher = better) |

---

## ğŸ§  Summary

| Step                     | Action Needed                                           |
| ------------------------ | ------------------------------------------------------- |
| ğŸ“¦ Provision Resource    | AI Vision (standalone or via Foundry/multi-service)     |
| ğŸ” Choose Authentication | API Key or Microsoft Entra ID                           |
| ğŸ–¼ï¸ Send Image            | Binary or URL (JPEG, PNG, GIF, BMP, â‰¤ 4 MB, > 50Ã—50 px) |
| ğŸ¯ Specify Feature       | Use `VisualFeatures.READ` or `features=read`            |
| ğŸ“¤ Parse Response        | Use SDK response or JSON for lines, words, confidence   |
