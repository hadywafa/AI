# 🧾 **Azure Computer Vision OCR – Read Printed and Handwritten Text (Image to Text)**

Azure’s `Read API` (under the **Computer Vision** service) uses advanced OCR (Optical Character Recognition) to extract **printed** and **handwritten** text from images — including photos, scanned documents, handwriting, and even whiteboard content.

---

## 🧠 What’s Special About the Read API?

Unlike older OCR models (e.g., `ocr()` method), the **Read API** is:

- ✅ More accurate
- 🌍 Works with images from **URLs or local files**
- ✍️ Supports **handwriting**, cursive, and multiple languages
- 🔄 Returns results asynchronously (so we poll until results are ready)

---

## 🔐 Step 1: Authentication and Setup

We first authenticate with Azure using a Computer Vision **endpoint** and **key** from your Cognitive Services resource.

```python
from azure.cognitiveservices.vision.computervision import ComputerVisionClient
from msrest.authentication import CognitiveServicesCredentials
import os

AZURE_VISION_ENDPOINT = os.getenv("AZURE_VISION_ENDPOINT")
AZURE_VISION_KEY = os.getenv("AZURE_VISION_KEY")

computervision_client = ComputerVisionClient(
    AZURE_VISION_ENDPOINT,
    CognitiveServicesCredentials(AZURE_VISION_KEY)
)
```

✅ `os.getenv()` helps load credentials from `.env` file (safer than hardcoding).

---

## 📸 Step 2: OCR from a Remote Image (URL)

```python
read_image_url = "https://learn.microsoft.com/azure/ai-services/computer-vision/media/quickstarts/presentation.png"
read_response = computervision_client.read(read_image_url, raw=True)
```

- We pass an **image URL** to `read()`
- `raw=True` is needed to access response headers
- Response header includes an **Operation-Location URL** — used to track async result status

### 🔁 Polling for Results

```python
operation_id = read_response.headers["Operation-Location"].split("/")[-1]

while True:
    read_result = computervision_client.get_read_result(operation_id)
    if read_result.status not in ["notStarted", "running"]:
        break
    time.sleep(1)
```

- We extract the **operation ID**
- We call `get_read_result()` in a loop until status is `succeeded` or `failed`
- `sleep(1)` prevents hammering the API too fast

---

## 📤 Step 3: Parsing the OCR Result

```python
if read_result.status == OperationStatusCodes.succeeded:
    for text_result in read_result.analyze_result.read_results:
        for line in text_result.lines:
            print(line.text)
            print(line.bounding_box)
```

Each line object includes:

- 🧾 `text`: actual line of text
- 📐 `bounding_box`: coordinates of the text in the image, as a list of 8 numbers (4 points)

🧠 Example Output:

```ini
Azure Cognitive Services
[100, 75, 580, 75, 580, 130, 100, 130]
```

---

### 📂 Step 4: OCR from Local Image

Now let’s process an image stored locally, such as a **handwritten note** or **scanned receipt**.

```python
local_image = open("./Handwritten_Notes/note.jpg", "rb")
read_response = computervision_client.read_in_stream(local_image, raw=True)
```

- `read_in_stream()` reads image from binary stream (`open(..., "rb")`)
- The rest is **identical** to the remote example: extract operation ID, poll, and parse

---

## 🎯 Summary of Key Methods

| Method                          | Use Case                          |
| ------------------------------- | --------------------------------- |
| `read(url)`                     | OCR for remote images via URL     |
| `read_in_stream(image)`         | OCR for local image files         |
| `get_read_result(operation_id)` | Polls until OCR results are ready |

---

## 💡 Real-World Use Cases

| Use Case                     | Benefit                            |
| ---------------------------- | ---------------------------------- |
| Digitizing scanned invoices  | Turn printed text into usable data |
| Processing handwritten forms | Extract cursive notes digitally    |
| Reading signboards in images | Great for accessibility + indexing |
| Analyzing whiteboards        | Store and search meeting content   |

---

## 🧪 Bonus Tips

- ✅ Use high-resolution, well-lit images
- 💬 Use OCR with **language hints** for better multilingual support
- 🧾 Combine with Azure Form Recognizer if layout matters (tables, forms)
