# 🤖 Working with Multimodal Models in Azure AI Foundry

Multimodal models allow you to submit prompts that include _text, images,_ and (in some cases) _audio_. These models can process and reason over multiple types of input simultaneously, making them ideal for vision-enabled chatbots and intelligent apps.

---

## 🎯 What Are Multimodal Models?

Multimodal generative AI models go beyond text-only input/output. They support prompts with:

- 📝 Text
- 🖼️ Images (via URL or base64)
- 🎧 Audio (in some cases, e.g. whisper or gpt-4o)

### ✅ Supported Models in Azure AI Foundry

| Model Name                    | Capabilities                                                 |
| ----------------------------- | ------------------------------------------------------------ |
| **Phi-4-multimodal-instruct** | Lightweight, optimized for text + image prompts              |
| **GPT-4o**                    | OpenAI's most advanced multimodal model (text, image, audio) |
| **GPT-4o-mini**               | Faster/cheaper version of GPT-4o, with same modalities       |

> 🔗 Tip: See the **Model catalog** in [Azure AI Foundry Portal](https://ai.azure.com) to explore more options.

---

## 🧪 Testing Multimodal Models

After deployment, you can test a model using the **Playground**:

1. Upload an image using the 📎 (attach) button
2. Add a text prompt like: `"What desserts could I make with this fruit?"`
3. Submit to see the model generate a vision-aware answer

> 🧠 Hint: Vision prompts work best with high-quality images and a descriptive question.

---

## 🧱 JSON Structure of a Multimodal Prompt

```json
{
  "messages": [
    { "role": "system", "content": "You are a helpful assistant." },
    {
      "role": "user",
      "content": [
        { "type": "text", "text": "Describe this picture:" },
        { "type": "image_url", "image_url": { "url": "https://..." } }
      ]
    }
  ]
}
```

> 🔄 **image_url** can be either an external URL or a base64-encoded image using a `data:` URL scheme.

---

## 🧑‍💻 Build a Vision-Based Chat App

### 🔌 Required SDKs

| Language | SDKs                                                        |
| -------- | ----------------------------------------------------------- |
| Python   | `azure-ai-projects`, `azure-ai-inference`, `azure-identity` |
| C#       | `Azure.AI.Projects`, `Azure.AI.Inference`, `Azure.Identity` |

### 🔑 Configuration (example: Python)

Update `.env` file:

```ini
PROJECT_CONNECTION=<your_connection_string>
MODEL_DEPLOYMENT=<your_model_name>
```

---

## 🔄 Vision Prompt with URL-based Image (Python)

```python
from azure.ai.inference.models import *
from azure.ai.projects import AIProjectClient
from azure.identity import DefaultAzureCredential

image_url = "https://github.com/MicrosoftLearning/.../orange.jpeg"
data_url = f"data:image/jpeg;base64,{base64_encoded_data}"

response = chat_client.complete(
    messages=[
        SystemMessage("You are a helpful assistant."),
        UserMessage(content=[
            TextContentItem(text="What is this fruit?"),
            ImageContentItem(image_url=ImageUrl(url=data_url))
        ])
    ]
)
print(response.choices[0].message.content)
```

---

## 📁 Vision Prompt with Local Image (C#)

```csharp
byte[] imageBytes = File.ReadAllBytes("mystery-fruit.jpeg");
var binaryImage = new BinaryData(imageBytes);

ChatCompletionsOptions requestOptions = new()
{
    Messages = {
        new ChatRequestSystemMessage("You are a helpful assistant."),
        new ChatRequestUserMessage([
            new ChatMessageTextContentItem("Describe this fruit"),
            new ChatMessageImageContentItem(bytes: binaryImage, mimeType: "image/jpeg")
        ]),
    },
    Model = modelDeployment
};
```

---

## 📦 Use Cases for Multimodal AI

| Scenario            | Description                                     |
| ------------------- | ----------------------------------------------- |
| 🛒 Grocery Bot      | Upload a fruit photo and ask for recipes        |
| 🖼️ Museum Assistant | Ask questions about artworks in uploaded images |
| 🔍 Visual Q\&A      | Upload a chart or graph and ask what it means   |

---

## 🧼 Clean Up

To avoid unnecessary costs:

1. In the Azure portal, navigate to your resource group
2. Click **Delete resource group** and confirm

---

## 📝 Summary Table

| Concept                  | Key Points                                                  |
| ------------------------ | ----------------------------------------------------------- |
| **Multimodal Support**   | Text + image (audio in GPT-4o)                              |
| **Prompt Format**        | JSON with `text` and `image_url` fields                     |
| **Model Deployment**     | Use Foundry portal or API                                   |
| **SDKs**                 | `azure-ai-inference`, `azure-ai-projects`, `azure-identity` |
| **Use Case**             | Vision-enabled chat apps                                    |
| **Base64 Image Support** | Format: `data:image/jpeg;base64,...`                        |
