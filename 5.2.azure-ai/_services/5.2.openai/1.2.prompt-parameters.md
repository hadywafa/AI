# ğŸ§  Prompt Parameters in Azure OpenAI Studio

These parameters control **how the model thinks, talks, and behaves** during inference (when generating responses).

Letâ€™s go one by one, with examples, metaphors, and practical tips:

---

## âœ… Summary Table

| Parameter             | What It Does                         | Good For                          |
| --------------------- | ------------------------------------ | --------------------------------- |
| **System Message**    | Sets the AIâ€™s role or tone           | Character/personality tuning      |
| **Past Messages**     | How much chat history AI remembers   | Chatbots, continuity              |
| **Max Response**      | Max length of reply                  | Cost control, formatting          |
| **Temperature**       | Controls creativity                  | Creative writing, story, poems    |
| **Top P**             | Limits randomness (nucleus sampling) | Factual or focused answers        |
| **Stop Sequence**     | Ends generation at a certain word    | API responses, structured outputs |
| **Frequency Penalty** | Prevents repeated **words**          | Summary, blog, doc generation     |
| **Presence Penalty**  | Prevents repeated **ideas**          | Brainstorming, topic generation   |

---

## ğŸ§© 1. **System Message** (ğŸ§™ Prompt Personality)

> Controls: The _role_, behavior, or tone of the assistant  
> Example: `"You are a helpful assistant"`

### ğŸ“˜ What is it?

Itâ€™s like **setting the character and behavior** of the assistant **before** the conversation starts.

### ğŸ§  Analogy:

Youâ€™re hiring an AI. The **system message** is the **job description + personality** you assign:

- â€œYou are a lawyerâ€
- â€œYou are sarcasticâ€
- â€œYou respond only with bullet pointsâ€
- â€œYou are a pirate speaking only pirate slangâ€

### ğŸ”¥ Example:

```json
"You are a helpful assistant that always answers in haiku format."
```

> The system message never shows in output, but it influences **everything** the AI says.

---

## ğŸ•°ï¸ 2. **Past Messages Included** (ğŸ’¬ Memory Window)

> Controls: How many prior Q\&As the model remembers per request.  
> Example: `5` messages means 5 previous turns (user + AI) are included.

### ğŸ“˜ What is it?

This controls **how much context** from the past the model uses for answering your current question.

### ğŸ§  Analogy:

Think of this like the AIâ€™s **short-term memory**. You can say:

- â€œForget everything, only care about my current questionâ€
- Or: â€œRemember the last 5 things I saidâ€

### ğŸ”¥ Tip:

- In **RAG apps**, a smaller context (2â€“5) helps performance.
- For **chatbots**, higher context (8â€“10) improves continuity.

---

## ğŸ“ 3. **Max Response Tokens** (ğŸ§® How Long Should the Answer Be?)

> Controls: Maximum **length** of AI's response
> Example: `500 tokens` â‰ˆ 350â€“400 words.

### ğŸ“˜ What is it?

This limits how **long** the response can be (in tokens, not characters).

> âš ï¸ One token â‰ˆ 4 characters â‰ˆ 0.75 words (in English)

### ğŸ§  Analogy:

Youâ€™re writing an article, and the editor says, â€œYou get 200 words max.â€ Thatâ€™s what this does.

### ğŸ”¥ Tip:

- Short answers? Use 50â€“100
- Detailed summaries or documents? 500â€“1000
- Watch your quota! More tokens = ğŸ’¸ more \\\\\\\\\\\\\\\\\\\\\$\\\\\\\\\\\\\\\\\\\\\$\$

---

## ğŸ”¥ 4. **Temperature** (ğŸ² Creativity Level)

> Controls: How **random** or **creative** the AI is
> Range: 0.0 â€“ 2.0 (default: **0.7**)

### ğŸ“˜ What is it?

Higher temperature = More _creative_, _random_, or _risky_ answers
Lower = More _factual_, _precise_, _safe_

### ğŸ§  Analogy:

Itâ€™s like how free the AI is allowed to think:

- `0.0` = â€œJust the facts, pleaseâ€
- `1.0` = â€œBe creative, explore ideasâ€
- `2.0` = â€œYou're drunk, write a fairytale!â€

### ğŸ”¥ Example:

| Prompt                          | Response (Temp 0.0) | Response (Temp 1.5)            |
| ------------------------------- | ------------------- | ------------------------------ |
| "Whatâ€™s the capital of France?" | "Paris"             | "The baguette kingdom, Paris!" |

---

## ğŸ¯ 5. **Top P (Nucleus Sampling)**

> Controls: Another way to **limit randomness**  
> Range: 0.1 â€“ 1.0

### ğŸ“˜ What is it?

Top P tells the model to only consider the **top X% most likely words** during generation.

> Example: Top P = 0.9 â†’ Only use words that together make up 90% of probability mass.

### ğŸ§  Analogy:

Like **choosing from a shorter menu** of possible words to say.

### ğŸ”¥ Tip:

- **Top P = 1.0** â†’ Consider all possible words
- **Top P = 0.5** â†’ Narrowed, focused generation
- Works best when tuned **with temperature**

---

## ğŸ›‘ 6. **Stop Sequences** (ğŸš« End of Generation)

> Controls: What **word or character** makes the model stop replying  
> Example: `"###"` or `"The End"`

### ğŸ“˜ What is it?

It defines **when to stop generating** tokens â€” like a punctuation mark the model obeys.

### ğŸ§  Analogy:

Itâ€™s like a teacher saying, â€œWhen I say â€˜Stopâ€™, stop reading aloud.â€

### ğŸ”¥ Use Cases:

- Ending code generation: `\n\n`
- Finishing multi-part answers: `"---"`
- Prevent long rambles

---

## ğŸ” 7. **Frequency Penalty** (â™»ï¸ Donâ€™t Repeat Too Much)

> Controls: Reduce repetition of exact same **words**  
> Range: 0.0 â€“ 2.0

### ğŸ“˜ What is it?

This penalizes the model from repeating **the same tokens** over and over again.

### ğŸ§  Analogy:

If the model keeps saying "Paris is the capital of France" 5 times â€” this fixes it.

### ğŸ”¥ Tip:

- Set to **0.5â€“1.0** if your output is **repetitive**
- For story generation, helps keep content diverse

---

## ğŸ­ 8. **Presence Penalty** (ğŸš« Donâ€™t Talk About the Same Stuff)

> Controls: Discourage repetition of **topics or themes**  
> Range: 0.0 â€“ 2.0

### ğŸ“˜ What is it?

It penalizes the model if it tries to talk about a topic **it already mentioned** â€” keeps conversations moving.

### ğŸ§  Analogy:

You ask â€œTell me about AIâ€ and it keeps going back to â€œChatGPTâ€ in every answer. Presence penalty says, â€œLetâ€™s talk about something **new**!â€

### ğŸ”¥ Tip:

- Use **0.5â€“1.0** when generating multiple ideas (e.g. headlines, topics, FAQs)
- Great for **creative writing**, brainstorming

---

## ğŸ§ª Example Prompt Configuration (for a polite helper)

```json
{
  "model": "gpt-35-turbo",
  "system_message": "You are a polite AI assistant that speaks in clear short answers.",
  "temperature": 0.5,
  "top_p": 0.9,
  "max_tokens": 300,
  "presence_penalty": 0.6,
  "frequency_penalty": 0.3,
  "stop_sequences": ["###"],
  "messages": [
    {
      "role": "user",
      "content": "What is the capital of France?"
    }
  ]
}
```
