# 🧠 Azure AI Language Service – Text Analytics Features with Python SDK

_Fully Explained Demos for AI-102 Preparation and Real Projects!_

---

## 📦 Prerequisites

Before diving into the demos, make sure to install the required packages:

```bash
pip install azure-ai-textanalytics python-dotenv
```

And prepare a `.env` file with the following values:

```env
AZURE_LANGUAGE_KEY=your_key_here
AZURE_LANGUAGE_ENDPOINT=https://your-endpoint.cognitiveservices.azure.com/
```

---

## 🧪 Test Document

This is the sample document we’ll use for all the demos:

```python
text = """Satya Nadella visited Microsoft headquarters in Redmond last week to discuss future AI strategy.
His phone number is 456-908-670. Microsoft Azure provides scalable AI services."""
```

---

## 🧰 Common Setup for All Features

```python
import os
from dotenv import load_dotenv
from azure.core.credentials import AzureKeyCredential
from azure.ai.textanalytics import TextAnalyticsClient

# Load credentials
load_dotenv()
endpoint = os.getenv("AZURE_LANGUAGE_ENDPOINT")
key = os.getenv("AZURE_LANGUAGE_KEY")
credential = AzureKeyCredential(key)

client = TextAnalyticsClient(endpoint=endpoint, credential=credential)
docs = [text]
```

---

## 🔍 1. Language Detection

```python
response = client.detect_language(documents=docs)[0]
print(f"Language: {response.primary_language.name}, Confidence: {response.primary_language.confidence_score}")
```

🧾 **Output:**

```json
{
  "language": "English",
  "confidence": 0.99
}
```

📌 **Use Case:** Locale switching, multilingual analytics

---

## 🗝️ 2. Key Phrase Extraction

```python
response = client.extract_key_phrases(documents=docs)[0]
print("Key Phrases:", response.key_phrases)
```

🧾 **Output:**

```json
["Satya Nadella", "Microsoft headquarters", "Redmond", "AI strategy", "phone number"]
```

📌 **Use Case:** Tagging, indexing, summarization

---

## 😐 3. Sentiment Analysis (with Confidence Scores)

```python
response = client.analyze_sentiment(documents=docs)[0]
print(f"Sentiment: {response.sentiment}, Scores: {response.confidence_scores}")
```

🧾 **Output:**

```json
{
  "sentiment": "neutral",
  "scores": {
    "positive": 0.07,
    "neutral": 0.88,
    "negative": 0.05
  }
}
```

📌 **Use Case:** Product reviews, chatbot tuning, trend analysis

---

## 🕵️ 4. Named Entity Recognition (NER)

```python
response = client.recognize_entities(documents=docs)[0]
for entity in response.entities:
    print(f"{entity.text} ({entity.category}, {entity.subcategory}) - {entity.confidence_score}")
```

🧾 **Output:**

```json
[
  { "text": "Satya Nadella", "category": "Person", "confidence": 1.0 },
  { "text": "Microsoft", "category": "Organization", "confidence": 1.0 },
  { "text": "Redmond", "category": "Location", "confidence": 1.0 },
  { "text": "last week", "category": "DateTime", "subcategory": "DateRange", "confidence": 1.0 }
]
```

📌 **Use Case:** Metadata enrichment, entity tagging

---

## 🌐 5. Linked Entity Recognition

```python
response = client.recognize_linked_entities(documents=docs)[0]
for entity in response.entities:
    print(f"{entity.name} → {entity.url}")
```

🧾 **Output:**

```json
{
  "Microsoft Azure": "https://en.wikipedia.org/wiki/Microsoft_Azure"
}
```

📌 **Use Case:** Wiki linking, semantic search, disambiguation

---

## 🔒 6. PII (Personally Identifiable Information) Recognition

```python
response = client.recognize_pii_entities(documents=docs)[0]
print(f"Redacted Text: {response.redacted_text}")
for entity in response.entities:
    print(f"{entity.text} ({entity.category}) - Confidence: {entity.confidence_score}")
```

🧾 **Output:**

```json
{
  "redactedText": "His phone number is ***********",
  "entities": [
    {
      "text": "456-908-670",
      "category": "PhoneNumber",
      "confidence": 0.91
    }
  ]
}
```

📌 **Use Case:** GDPR/CCPA compliance, secure data pipelines

---

## ✂️ 7. Extractive Summarization (Async)

> Works best for long texts (min. 1000 characters)

```python
from azure.ai.textanalytics import ExtractSummaryAction

poller = client.begin_analyze_actions(
    documents=[text * 10],  # Repeat text to reach min character count
    actions=[ExtractSummaryAction(max_sentence_count=2)],
)
result = poller.result()
for doc in result:
    for action in doc:
        for sentence in action.sentences:
            print(sentence.text)
```

🧾 **Output:**

```json
["Satya Nadella visited Microsoft headquarters in Redmond...", "Microsoft Azure provides scalable AI services."]
```

📌 **Use Case:** TL;DR, contract summarization, support emails

---

## 📊 Summary Table of Features & SDK Methods

| 🧠 Feature               | SDK Method                    | Result                   |
| ------------------------ | ----------------------------- | ------------------------ |
| Language Detection       | `detect_language()`           | Language + Confidence    |
| Key Phrases              | `extract_key_phrases()`       | List of Phrases          |
| Sentiment Analysis       | `analyze_sentiment()`         | Sentiment + Scores       |
| Named Entity Recognition | `recognize_entities()`        | Entity List + Categories |
| Linked Entities          | `recognize_linked_entities()` | Wikipedia Links          |
| PII Recognition          | `recognize_pii_entities()`    | Redacted + PII Entities  |
| Extractive Summarization | `begin_analyze_actions()`     | Summary Sentences        |

---

## ✅ AI-102 Certification Tips

- 📌 **All of these** are part of **Azure AI Language (Text Analytics)** under a single client.
- ⚙️ Most features are **sync**, except summarization which is **async**.
- 🚨 **NER ≠ PII**: NER shows public info like people or cities, PII shows sensitive info like SSN or emails.
- 📄 Always include **confidence scores** in production apps.
- 🛡️ PII detection is **critical** for legal compliance.
