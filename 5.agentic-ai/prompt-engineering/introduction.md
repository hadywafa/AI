# ðŸ“˜ Phase 1 â€“ Core Prompting Techniques

_â€œMake the AI talk like a pro (or a pirate) with your words alone.â€!_

---

## ðŸ§­ Overview

### ðŸ”¹ **Official Definition:**

> **Prompt engineering** is the art and science of crafting input to Large Language Models (LLMs) to produce desired and predictable output.

This phase will teach you the **building blocks of effective prompting**, from basic styles to advanced prompting modes like **Few-shot** and **Chain-of-Thought** (CoT).

You'll learn how to:

- ðŸŽ¯ Give clear instructions
- ðŸ§  Inject context or memory
- âœï¸ Format output like tables, JSON, etc.
- ðŸ§™â€â™‚ï¸ Guide the modelâ€™s tone and behavior like a pro

---

## ðŸ§± Core Prompting Types

### ðŸŸ¡ 1. **Zero-Shot Prompting** ðŸ¤–

_"Do this, please. No example needed."!_

### âœ… What it is

Give the model a task with **no examples**, just instructions.

### ðŸ“¦ Example

> ðŸ’¬ `"Translate this into French: Where is the nearest pharmacy?"`

### âœ… Good for

- Simple commands
- When you donâ€™t have training data

---

### ðŸŸ¢ 2. **Few-Shot Prompting** ðŸ§ 

_"Here's how it's done, now your turn!"!_

### âœ… What it is

Provide a few **examples** in the prompt to show the pattern you want.

### ðŸ“¦ Example

```txt
English: Hello
French: Bonjour

English: Thank you
French: Merci

English: Good night
French: ??
```

ðŸŽ¯ LLMs are like parrots with pattern-recognition superpowers. Give examples, and it mimics them.

---

### ðŸ”µ 3. **Chain-of-Thought (CoT) Prompting** ðŸ§©

_"Letâ€™s think step by step..."!_

### âœ… What it is

Ask the model to **think aloud** before answering. This boosts performance on logic-heavy tasks.

### ðŸ“¦ Example

> ðŸ’¬ `"If a train leaves at 4 PM and takes 3 hours to reach its destination, when does it arrive? Let's think step-by-step."`

ðŸ§  The model will now reason:

> - Train leaves at 4 PM
> - Takes 3 hours
> - Arrives at **7 PM**

ðŸª„ Itâ€™s magic for math, logic, and anything with multi-step reasoning.

---

### ðŸ”´ 4. **Role Prompting** ðŸŽ­

_"You are a lawyer / doctor / pirate / Shakespeare..."!_

### âœ… What it is

Set the **persona** of the assistant using a system prompt.

### ðŸ“¦ Example

```json
{ "role": "system", "content": "You are a sarcastic yet helpful tech support bot." }
```

Then the assistant will answer:

> "Oh, you turned it off and on again? Brilliant. Here's how to fix it for real..."

---

### ðŸŸ£ 5. **Instruction + Formatting Constraints** ðŸ—‚ï¸

_"Give me a table / list / JSON / code block..."!_

### âœ… What it is

Explicitly tell the model how you want the response **structured**.

### ðŸ“¦ Example

> ðŸ’¬ `"Give me a list of 5 AWS services with their use case in table format."`

| AWS Service | Use Case                              |
| ----------- | ------------------------------------- |
| S3          | Store and retrieve any amount of data |
| Lambda      | Serverless function execution         |
| DynamoDB    | NoSQL key-value database              |
| EC2         | Virtual machine hosting               |
| CloudWatch  | Monitoring and logging AWS resources  |

---

## ðŸ§ª Bonus: Combine Techniques for Super Prompts âš¡

> ðŸ§™â€â™‚ï¸ Combine role + few-shot + CoT + formatting = _Chefâ€™s kiss prompt perfection._

```json
[
  {
    "role": "system",
    "content": "You're an expert AWS instructor who answers with JSON."
  },
  {
    "role": "user",
    "content": "Explain 3 AWS compute services. Include name, type, and description."
  }
]
```

Model replies:

```json
[
  {
    "name": "EC2",
    "type": "Virtual Machine",
    "description": "Scalable VMs for any workload"
  },
  ...
]
```

---

## ðŸ§° Mermaid Diagram: Prompting Modes at a Glance

```mermaid
graph TD
    A[Prompting] --> B[Zero-Shot]
    A --> C[Few-Shot]
    A --> D[Chain-of-Thought]
    A --> E[Role Prompting]
    A --> F[Instruction + Formatting]
    C --> G[Examples in Prompt]
    D --> H["Let's think step-by-step"]
    E --> I["You are a..."]
    F --> J[Tables / JSON / Markdown]
```

---

## ðŸ§ª Practice Lab Time

Try to write a prompt for each of these tasks below using the right technique:

| ðŸ§ª Task                                                | Recommended Prompt Style |
| ------------------------------------------------------ | ------------------------ |
| Translate sentence to Spanish                          | Zero-shot                |
| Classify tweets into â€œPositiveâ€, â€œNeutralâ€, â€œNegativeâ€ | Few-shot                 |
| Solve math word problems                               | Chain-of-Thought         |
| Summarize resume as an HR recruiter                    | Role + Formatting        |
| Output must be valid YAML                              | Instruction + Constraint |

Drop your answers here when you're done â€” and Iâ€™ll give feedback or optimize them with you. ðŸ’¬

---

## ðŸŽ“ Up Next

> **Phase 2: Advanced Prompt Structuring & Format Control**
> Weâ€™ll learn how to:

- Force the model to output **clean JSON**
- Use **delimiters**, **anchors**, and **escape hatches**
- Handle **multi-part input**
- Chain prompts to mimic memory
